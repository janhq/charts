imageTag: 0.0.1-2023.1.1
# DO NOT CHANGE THE LINE ABOVE. MAKE ALL CHANGES BELOW

# Global pvc for all workload
pvc:
  enabled: false
  name: ""
  storageClassName: ""
  volumeHandle: ""
  capacity: "1Gi"

# Global image pull secret
imagePullSecrets: []

nameOverride: "common-module"
fullnameOverride: "common-module"

serviceAccount:
  create: true
  annotations: {}
  name: "common-module-service-account"

podDisruptionBudget:
  create: true
  minAvailable: 1

instrumentation:
  sampler: 1
  xray: false
  endpoint: "http://otel-collector:4318"

workloads:
  - name: api
    image:
      repository: docker.io
      pullPolicy: IfNotPresent

    # command: ["/bin/sh", "-c"]
    # args: ["python3 main.py"]

    replicaCount: 1
    ports:
      containerPort: 3000

    strategy:
      canary:
        steps:
          - setWeight: 50
          - pause: { duration: 1m }

    ingress:
      enabled: false
      className: ""
      annotations:
        nginx.ingress.kubernetes.io/proxy-body-size: "100m"
        nginx.ingress.kubernetes.io/proxy-read-timeout: "1800"
        nginx.ingress.kubernetes.io/proxy-send-timeout: "1800"
        kubernetes.io/ingress.class: nginx
      hosts:
        - host: common-api.menlo.ai
          paths:
            - path: /
              pathType: Prefix
      tls: []

    extraIngress:
      enabled: false
      className: ""
      annotations:
        nginx.ingress.kubernetes.io/proxy-body-size: "100m"
        nginx.ingress.kubernetes.io/proxy-read-timeout: "1800"
        nginx.ingress.kubernetes.io/proxy-send-timeout: "1800"
        kubernetes.io/ingress.class: nginx
      hosts:
        - host: common-api-extra.menlo.ai
          paths:
            - path: /
              pathType: Prefix
      tls: []

    instrumentation:
      enabled: false
      type: python

    podAnnotations: {}

    podSecurityContext: {}

    securityContext: {}

    service:
      extenalLabel: {}
      type: ClusterIP
      port: 3000
      targetPort: 3000

    resources:
      limits:
        memory: 512M
      requests:
        cpu: 50m
        memory: 300M

    # volumes:
    #   - name: shared-data
    #     persistentVolumeClaim:
    #       claimName: common-module-pvc

    # volumeMounts:
    #   - name: shared-data
    #     mountPath: /storage

    env: []
    configMapName: "test"
    externalSecret:
      create: false
      name: "common-secret"
      annotations: {}
      # Currently, this chart only support 2 backends: vaults, secretsManager
      backendType: vaults
      secretStoreRefName: vault-secret-manager
      secretStoreRefKind: ClusterSecretStore
      roleArn: ""
      controllerId: ""
      region: "us-east-1"
      data: []
      dataFrom: []
      template: {}

    lifecycle: {}
    autoscaling:
      enabled: true
      minReplicas: 1
      maxReplicas: 3
      targetCPUUtilizationPercentage: 80
      targetMemoryUtilizationPercentage: 80

    kedaScaling:
      enabled: false # ignore if autoscaling.enable = true
      cooldownPeriod: 30
      pollingInterval: 2
      minReplicas: 1
      maxReplicas: 5
      metricName: celery_queue_length
      query: celery_queue_length{queue_name="myqueue"} # change queue_name here
      serverAddress: http://prometheus-stag-kube-prome-prometheus.monitoring.svc:9090
      threshold: "3"

    vpa:
      enabled: true
      updateMode: "Off"
      resourcePolicy: {}
    nodeSelector: {}

    tolerations: []

    podSecurityGroup:
      enabled: false
      securitygroupid: []

    # Reloader Option
    reloader: "true"
